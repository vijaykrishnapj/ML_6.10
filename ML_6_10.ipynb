{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BeGJ8X_yeiw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd;\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CSE303/Lab-5/melbourne_housing_raw.csv')\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "for column in data.keys():\n",
        "  print(data[column].dtype)\n",
        "  if data[column].dtype == 'object':\n",
        "    data[column] = label_encoder.fit_transform(data[column])\n",
        "x=data.drop('Propertycount',axis=1)\n",
        "y=data['Propertycount']\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "if y.isnull().any():\n",
        "    y = y.dropna()\n",
        "    x = x.loc[y.index]\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "def evaluate_model(X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return mean_absolute_error(y_test, y_pred)\n",
        "mae_list = []\n",
        "num_features_list = []\n",
        "current_features = list(X_train.columns)\n",
        "initial_mae = evaluate_model(X_train[current_features], X_test[current_features], y_train, y_test)\n",
        "mae_list.append(initial_mae)\n",
        "num_features_list.append(len(current_features))\n",
        "print(f\"initial mae with all features: {initial_mae}\")\n",
        "for _ in range(len(current_features) - 1):\n",
        "    importances = model.feature_importances_\n",
        "    least_important_idx = np.argmin(importances)\n",
        "    least_important_feature = current_features[least_important_idx]\n",
        "    current_features.pop(least_important_idx)\n",
        "    new_mae = evaluate_model(X_train[current_features], X_test[current_features], y_train, y_test)\n",
        "\n",
        "\n",
        "    mae_list.append(new_mae)\n",
        "    num_features_list.append(len(current_features))\n",
        "    print(f\"removed {least_important_feature}, mae: {new_mae}, features left: {len(current_features)}\")\n",
        "plt.plot(num_features_list, mae_list, marker='o')\n",
        "plt.title('Impact of Feature Elimination on Model Accuracy')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Mean Absolute Error (MAE)')\n",
        "plt.gca().invert_xaxis()\n",
        "plt.show()\n"
      ]
    }
  ]
}